# Landmark-Detection and Robot-Tracking(SLAM)

## Project Overview:
- In this project, We will implement SLAM (Simultaneous Localization and Mapping) for a 2 dimensional world! Weâ€™ll combine what we know about robot sensor measurements and movement to create a map of an environment from only sensor and motion data gathered by a robot, over time. SLAM gives us a way to track the location of a robot in the world in real-time and identify the locations of landmarks such as buildings, trees, rocks, and other world features. This is an active area of research in the fields of robotics and autonomous systems.

![alt text](https://github.com/raunak222/Landmark-Detection-Tracking-SLAM/blob/master/images/download%20(10).png)

##  Motivation/Purpose: 
- Wee'll be localizing a robot in a 2D grid world. The basis for simultaneous localization and mapping (SLAM) is to gather information from a robot's sensors and motions over time, and then use information about measurements and motion to re-construct a map of the world
##  How to Use 
- Go through instruction [here](https://github.com/raunak222/Landmark-Detection-and-Robot-Tracking-SLAM/blob/master/Instruction.txt)

##  Some Visualization
 ![alt text](https://github.com/raunak222/Landmark-Detection-Tracking-SLAM/blob/master/images/downloahd.png)
 
 ![alt text](https://github.com/raunak222/Landmark-Detection-Tracking-SLAM/blob/master/images/download%20(9).png)


- Implement Sense function.
- Implement a function that initializes omega and xi.
- Implement Graph SLAM
## Developer 
  Raunak Sarada  
  - [Github](https://github.com/raunak222) 
  - [linkedin](https://www.linkedin.com/in/raunak-sarada)
## Resources 
- https://github.com/udacity/P3_Implement_SLAM
- https://blog.openmined.org

## Citation
- Udacity Computer Vision Nanodegree
